import requests
from bs4 import BeautifulSoup

# 游댳 Kl칤캜ov치 slova pro filtrov치n칤 캜l치nk콢
KEYWORDS = ["NATO","arm치da 캜esk칠 republiky", "arm치da","arm치dn칤", "voj치ci","voj치k콢", "A캛R", "obrana", "ministerstvo obrany", "vojensk칠", "Vojen코t칤", "z치sah", "cvi캜en칤", "voj치k", "st콏elb캩"]

def contains_keywords(text):
    """Ov캩콏칤, zda text obsahuje n캩kter칠 z kl칤캜ov칳ch slov"""
    return any(keyword.lower() in text.lower() for keyword in KEYWORDS)

def scrape_denik():
    URL = "https://www.denik.cz/z_domova/"
    response = requests.get(URL)
    articles = []

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        news_items = soup.find_all('a', class_='no-underline hover:text-primary-2 text-inky')

        for item in news_items:
            # Extrahov치n칤 n치zvu 캜l치nku z tagu <h2>
            title_tag = item.find('h2')
            if title_tag:
                title = title_tag.get_text(strip=True)
                # Z칤sk치n칤 odkazu z atributu href
                link = item['href']
                if not link.startswith("http"):
                    link = f"https://www.denik.cz{link}"
                # Filtrov치n칤 캜l치nk콢 na z치klad캩 kl칤캜ov칳ch slov
                if contains_keywords(title):
                    articles.append({"title": title, "link": link, "source": "denik.cz"})
    
    return articles

print(scrape_denik())

